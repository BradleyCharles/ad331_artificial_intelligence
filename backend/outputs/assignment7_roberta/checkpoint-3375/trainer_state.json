{
  "best_metric": 0.972,
  "best_model_checkpoint": "outputs/assignment7_roberta/checkpoint-1125",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 3375,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 1.3340190649032593,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.7007,
      "step": 10
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.8752999901771545,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.6865,
      "step": 20
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.4065897464752197,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.6954,
      "step": 30
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 2.6209194660186768,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.6902,
      "step": 40
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.4127751588821411,
      "learning_rate": 0.0001111111111111111,
      "loss": 0.6439,
      "step": 50
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.274609088897705,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.4483,
      "step": 60
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 9.437146186828613,
      "learning_rate": 0.00015555555555555556,
      "loss": 0.433,
      "step": 70
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 8.802699089050293,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.2819,
      "step": 80
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.737595558166504,
      "learning_rate": 0.0002,
      "loss": 0.3217,
      "step": 90
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 3.020366907119751,
      "learning_rate": 0.0002222222222222222,
      "loss": 0.3438,
      "step": 100
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 6.522631645202637,
      "learning_rate": 0.00024444444444444443,
      "loss": 0.444,
      "step": 110
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.37520170211792,
      "learning_rate": 0.0002666666666666667,
      "loss": 0.3375,
      "step": 120
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 2.440840244293213,
      "learning_rate": 0.0002888888888888889,
      "loss": 0.2963,
      "step": 130
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 4.665585517883301,
      "learning_rate": 0.0003111111111111111,
      "loss": 0.2949,
      "step": 140
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5990480780601501,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.3042,
      "step": 150
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 4.109732151031494,
      "learning_rate": 0.00035555555555555557,
      "loss": 0.3441,
      "step": 160
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 1.9060498476028442,
      "learning_rate": 0.00037777777777777777,
      "loss": 0.324,
      "step": 170
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.2894931733608246,
      "learning_rate": 0.0004,
      "loss": 0.3104,
      "step": 180
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 1.1362206935882568,
      "learning_rate": 0.0004222222222222222,
      "loss": 0.2622,
      "step": 190
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 4.588229179382324,
      "learning_rate": 0.0004444444444444444,
      "loss": 0.2841,
      "step": 200
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.632187843322754,
      "learning_rate": 0.00046666666666666666,
      "loss": 0.2526,
      "step": 210
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 1.7339062690734863,
      "learning_rate": 0.0004888888888888889,
      "loss": 0.2429,
      "step": 220
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 1.8498952388763428,
      "learning_rate": 0.000499290780141844,
      "loss": 0.2861,
      "step": 230
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.4377846717834473,
      "learning_rate": 0.000497872340425532,
      "loss": 0.2272,
      "step": 240
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 5.9854278564453125,
      "learning_rate": 0.0004964539007092199,
      "loss": 0.2917,
      "step": 250
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 1.3027735948562622,
      "learning_rate": 0.0004950354609929078,
      "loss": 0.3133,
      "step": 260
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0105628967285156,
      "learning_rate": 0.0004936170212765957,
      "loss": 0.2973,
      "step": 270
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 1.355081558227539,
      "learning_rate": 0.0004921985815602837,
      "loss": 0.2032,
      "step": 280
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 1.6863762140274048,
      "learning_rate": 0.0004907801418439716,
      "loss": 0.1674,
      "step": 290
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.8702752590179443,
      "learning_rate": 0.0004893617021276596,
      "loss": 0.348,
      "step": 300
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 4.027673721313477,
      "learning_rate": 0.0004879432624113475,
      "loss": 0.2716,
      "step": 310
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.19163314998149872,
      "learning_rate": 0.0004865248226950355,
      "loss": 0.2113,
      "step": 320
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0682876110076904,
      "learning_rate": 0.0004851063829787234,
      "loss": 0.2816,
      "step": 330
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 2.6967527866363525,
      "learning_rate": 0.00048368794326241133,
      "loss": 0.2354,
      "step": 340
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 1.0981802940368652,
      "learning_rate": 0.00048226950354609925,
      "loss": 0.3244,
      "step": 350
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.7437596321105957,
      "learning_rate": 0.00048085106382978723,
      "loss": 0.2161,
      "step": 360
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.361149400472641,
      "learning_rate": 0.0004794326241134752,
      "loss": 0.2238,
      "step": 370
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9515,
      "eval_f1": 0.9532530120481928,
      "eval_loss": 0.22705689072608948,
      "eval_precision": 0.92,
      "eval_recall": 0.989,
      "eval_runtime": 3.2801,
      "eval_samples_per_second": 609.739,
      "eval_steps_per_second": 38.109,
      "step": 375
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 1.258109211921692,
      "learning_rate": 0.00047801418439716314,
      "loss": 0.3468,
      "step": 380
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.23898841440677643,
      "learning_rate": 0.0004765957446808511,
      "loss": 0.208,
      "step": 390
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.22564582526683807,
      "learning_rate": 0.00047517730496453905,
      "loss": 0.28,
      "step": 400
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 2.3028178215026855,
      "learning_rate": 0.000473758865248227,
      "loss": 0.2147,
      "step": 410
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.71304851770401,
      "learning_rate": 0.0004723404255319149,
      "loss": 0.1938,
      "step": 420
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 1.3308311700820923,
      "learning_rate": 0.0004709219858156029,
      "loss": 0.2077,
      "step": 430
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 1.4345327615737915,
      "learning_rate": 0.0004695035460992908,
      "loss": 0.1868,
      "step": 440
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.036962628364563,
      "learning_rate": 0.00046808510638297874,
      "loss": 0.1858,
      "step": 450
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 6.033728122711182,
      "learning_rate": 0.00046666666666666666,
      "loss": 0.2216,
      "step": 460
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 0.17402128875255585,
      "learning_rate": 0.00046524822695035464,
      "loss": 0.1642,
      "step": 470
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.09791074693202972,
      "learning_rate": 0.00046382978723404257,
      "loss": 0.1392,
      "step": 480
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 1.9078340530395508,
      "learning_rate": 0.0004624113475177305,
      "loss": 0.232,
      "step": 490
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 2.7955615520477295,
      "learning_rate": 0.0004609929078014184,
      "loss": 0.2454,
      "step": 500
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.6578898429870605,
      "learning_rate": 0.0004595744680851064,
      "loss": 0.2331,
      "step": 510
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 6.513657569885254,
      "learning_rate": 0.00045815602836879433,
      "loss": 0.254,
      "step": 520
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 0.6565953493118286,
      "learning_rate": 0.00045673758865248226,
      "loss": 0.2534,
      "step": 530
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.24524948000907898,
      "learning_rate": 0.00045531914893617024,
      "loss": 0.2249,
      "step": 540
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 4.445156574249268,
      "learning_rate": 0.00045390070921985816,
      "loss": 0.2032,
      "step": 550
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 0.1516430824995041,
      "learning_rate": 0.0004524822695035461,
      "loss": 0.1797,
      "step": 560
    },
    {
      "epoch": 1.52,
      "grad_norm": 4.711146831512451,
      "learning_rate": 0.000451063829787234,
      "loss": 0.1371,
      "step": 570
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 0.06213860586285591,
      "learning_rate": 0.000449645390070922,
      "loss": 0.1775,
      "step": 580
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 0.35743001103401184,
      "learning_rate": 0.0004482269503546099,
      "loss": 0.2576,
      "step": 590
    },
    {
      "epoch": 1.6,
      "grad_norm": 5.042155742645264,
      "learning_rate": 0.00044680851063829785,
      "loss": 0.1991,
      "step": 600
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 0.11109598726034164,
      "learning_rate": 0.0004453900709219858,
      "loss": 0.2627,
      "step": 610
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 3.1654577255249023,
      "learning_rate": 0.00044397163120567376,
      "loss": 0.1954,
      "step": 620
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.3886061906814575,
      "learning_rate": 0.0004425531914893617,
      "loss": 0.2256,
      "step": 630
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 2.700378656387329,
      "learning_rate": 0.00044113475177304966,
      "loss": 0.2278,
      "step": 640
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 5.5558905601501465,
      "learning_rate": 0.00043971631205673764,
      "loss": 0.209,
      "step": 650
    },
    {
      "epoch": 1.76,
      "grad_norm": 4.138044834136963,
      "learning_rate": 0.00043829787234042557,
      "loss": 0.196,
      "step": 660
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 1.81257963180542,
      "learning_rate": 0.0004368794326241135,
      "loss": 0.2623,
      "step": 670
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 0.03933197632431984,
      "learning_rate": 0.0004354609929078014,
      "loss": 0.2067,
      "step": 680
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 8.804805755615234,
      "learning_rate": 0.0004340425531914894,
      "loss": 0.2162,
      "step": 690
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 1.9733492136001587,
      "learning_rate": 0.00043262411347517733,
      "loss": 0.2268,
      "step": 700
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 7.750497341156006,
      "learning_rate": 0.00043120567375886526,
      "loss": 0.255,
      "step": 710
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.0321884155273438,
      "learning_rate": 0.0004297872340425532,
      "loss": 0.2717,
      "step": 720
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 1.8373576402664185,
      "learning_rate": 0.00042836879432624116,
      "loss": 0.275,
      "step": 730
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 0.4031604826450348,
      "learning_rate": 0.0004269503546099291,
      "loss": 0.2057,
      "step": 740
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.209178447723389,
      "learning_rate": 0.000425531914893617,
      "loss": 0.1878,
      "step": 750
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9575,
      "eval_f1": 0.9589570255915016,
      "eval_loss": 0.21919968724250793,
      "eval_precision": 0.927170868347339,
      "eval_recall": 0.993,
      "eval_runtime": 3.2947,
      "eval_samples_per_second": 607.039,
      "eval_steps_per_second": 37.94,
      "step": 750
    },
    {
      "epoch": 2.026666666666667,
      "grad_norm": 2.621140718460083,
      "learning_rate": 0.000424113475177305,
      "loss": 0.1647,
      "step": 760
    },
    {
      "epoch": 2.0533333333333332,
      "grad_norm": 1.5493125915527344,
      "learning_rate": 0.0004226950354609929,
      "loss": 0.182,
      "step": 770
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.4318485260009766,
      "learning_rate": 0.00042127659574468085,
      "loss": 0.1751,
      "step": 780
    },
    {
      "epoch": 2.1066666666666665,
      "grad_norm": 1.1306718587875366,
      "learning_rate": 0.0004198581560283688,
      "loss": 0.2107,
      "step": 790
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 1.6332589387893677,
      "learning_rate": 0.00041843971631205676,
      "loss": 0.2038,
      "step": 800
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6397740840911865,
      "learning_rate": 0.0004170212765957447,
      "loss": 0.1722,
      "step": 810
    },
    {
      "epoch": 2.1866666666666665,
      "grad_norm": 0.6995317935943604,
      "learning_rate": 0.0004156028368794326,
      "loss": 0.1401,
      "step": 820
    },
    {
      "epoch": 2.2133333333333334,
      "grad_norm": 1.2786585092544556,
      "learning_rate": 0.00041418439716312054,
      "loss": 0.1939,
      "step": 830
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.10315434634685516,
      "learning_rate": 0.0004127659574468085,
      "loss": 0.1389,
      "step": 840
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 6.685894966125488,
      "learning_rate": 0.00041134751773049644,
      "loss": 0.1675,
      "step": 850
    },
    {
      "epoch": 2.2933333333333334,
      "grad_norm": 0.2867056727409363,
      "learning_rate": 0.00040992907801418437,
      "loss": 0.2045,
      "step": 860
    },
    {
      "epoch": 2.32,
      "grad_norm": 7.7000908851623535,
      "learning_rate": 0.00040851063829787235,
      "loss": 0.1973,
      "step": 870
    },
    {
      "epoch": 2.3466666666666667,
      "grad_norm": 1.7615951299667358,
      "learning_rate": 0.0004070921985815603,
      "loss": 0.1936,
      "step": 880
    },
    {
      "epoch": 2.3733333333333335,
      "grad_norm": 0.08140455186367035,
      "learning_rate": 0.0004056737588652482,
      "loss": 0.1332,
      "step": 890
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.10447713732719421,
      "learning_rate": 0.00040425531914893613,
      "loss": 0.1462,
      "step": 900
    },
    {
      "epoch": 2.4266666666666667,
      "grad_norm": 0.30062195658683777,
      "learning_rate": 0.00040283687943262417,
      "loss": 0.2181,
      "step": 910
    },
    {
      "epoch": 2.453333333333333,
      "grad_norm": 0.18652509152889252,
      "learning_rate": 0.0004014184397163121,
      "loss": 0.2524,
      "step": 920
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.24221442639827728,
      "learning_rate": 0.0004,
      "loss": 0.1989,
      "step": 930
    },
    {
      "epoch": 2.506666666666667,
      "grad_norm": 0.09507117420434952,
      "learning_rate": 0.00039858156028368795,
      "loss": 0.1508,
      "step": 940
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 0.03679557889699936,
      "learning_rate": 0.0003971631205673759,
      "loss": 0.1883,
      "step": 950
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.031266700476408005,
      "learning_rate": 0.00039574468085106385,
      "loss": 0.1406,
      "step": 960
    },
    {
      "epoch": 2.586666666666667,
      "grad_norm": 1.5703192949295044,
      "learning_rate": 0.0003943262411347518,
      "loss": 0.1811,
      "step": 970
    },
    {
      "epoch": 2.6133333333333333,
      "grad_norm": 3.874180555343628,
      "learning_rate": 0.00039290780141843976,
      "loss": 0.1834,
      "step": 980
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.4239379167556763,
      "learning_rate": 0.0003914893617021277,
      "loss": 0.1822,
      "step": 990
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.19986727833747864,
      "learning_rate": 0.0003900709219858156,
      "loss": 0.1972,
      "step": 1000
    },
    {
      "epoch": 2.6933333333333334,
      "grad_norm": 0.2861661911010742,
      "learning_rate": 0.00038865248226950354,
      "loss": 0.1797,
      "step": 1010
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 7.400167465209961,
      "learning_rate": 0.0003872340425531915,
      "loss": 0.1725,
      "step": 1020
    },
    {
      "epoch": 2.7466666666666666,
      "grad_norm": 0.21323654055595398,
      "learning_rate": 0.00038581560283687945,
      "loss": 0.1669,
      "step": 1030
    },
    {
      "epoch": 2.7733333333333334,
      "grad_norm": 2.4134204387664795,
      "learning_rate": 0.0003843971631205674,
      "loss": 0.216,
      "step": 1040
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.1736949384212494,
      "learning_rate": 0.0003829787234042553,
      "loss": 0.1359,
      "step": 1050
    },
    {
      "epoch": 2.8266666666666667,
      "grad_norm": 1.338593602180481,
      "learning_rate": 0.0003815602836879433,
      "loss": 0.1635,
      "step": 1060
    },
    {
      "epoch": 2.8533333333333335,
      "grad_norm": 6.281895160675049,
      "learning_rate": 0.0003801418439716312,
      "loss": 0.2025,
      "step": 1070
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.018966449424624443,
      "learning_rate": 0.00037872340425531913,
      "loss": 0.1512,
      "step": 1080
    },
    {
      "epoch": 2.9066666666666667,
      "grad_norm": 6.204486846923828,
      "learning_rate": 0.0003773049645390071,
      "loss": 0.1889,
      "step": 1090
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 10.061616897583008,
      "learning_rate": 0.00037588652482269504,
      "loss": 0.2476,
      "step": 1100
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.5354406833648682,
      "learning_rate": 0.00037446808510638297,
      "loss": 0.2049,
      "step": 1110
    },
    {
      "epoch": 2.986666666666667,
      "grad_norm": 0.20458994805812836,
      "learning_rate": 0.0003730496453900709,
      "loss": 0.1501,
      "step": 1120
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.972,
      "eval_f1": 0.972,
      "eval_loss": 0.18840990960597992,
      "eval_precision": 0.972,
      "eval_recall": 0.972,
      "eval_runtime": 3.2893,
      "eval_samples_per_second": 608.03,
      "eval_steps_per_second": 38.002,
      "step": 1125
    },
    {
      "epoch": 3.013333333333333,
      "grad_norm": 0.1105814054608345,
      "learning_rate": 0.0003716312056737589,
      "loss": 0.2071,
      "step": 1130
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.018460359424352646,
      "learning_rate": 0.0003702127659574468,
      "loss": 0.1278,
      "step": 1140
    },
    {
      "epoch": 3.066666666666667,
      "grad_norm": 0.07740744948387146,
      "learning_rate": 0.0003687943262411347,
      "loss": 0.1398,
      "step": 1150
    },
    {
      "epoch": 3.0933333333333333,
      "grad_norm": 2.4007456302642822,
      "learning_rate": 0.00036737588652482265,
      "loss": 0.1473,
      "step": 1160
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.481383353471756,
      "learning_rate": 0.00036595744680851063,
      "loss": 0.1842,
      "step": 1170
    },
    {
      "epoch": 3.1466666666666665,
      "grad_norm": 5.206497669219971,
      "learning_rate": 0.0003645390070921986,
      "loss": 0.145,
      "step": 1180
    },
    {
      "epoch": 3.1733333333333333,
      "grad_norm": 0.029673272743821144,
      "learning_rate": 0.00036312056737588654,
      "loss": 0.1607,
      "step": 1190
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.031556084752082825,
      "learning_rate": 0.0003617021276595745,
      "loss": 0.1456,
      "step": 1200
    },
    {
      "epoch": 3.2266666666666666,
      "grad_norm": 0.13732168078422546,
      "learning_rate": 0.00036028368794326245,
      "loss": 0.1183,
      "step": 1210
    },
    {
      "epoch": 3.2533333333333334,
      "grad_norm": 0.25221574306488037,
      "learning_rate": 0.0003588652482269504,
      "loss": 0.2169,
      "step": 1220
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 9.906716346740723,
      "learning_rate": 0.0003574468085106383,
      "loss": 0.1884,
      "step": 1230
    },
    {
      "epoch": 3.3066666666666666,
      "grad_norm": 0.02740335278213024,
      "learning_rate": 0.0003560283687943263,
      "loss": 0.1322,
      "step": 1240
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.0866478979587555,
      "learning_rate": 0.0003546099290780142,
      "loss": 0.1382,
      "step": 1250
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.1198965311050415,
      "learning_rate": 0.00035319148936170213,
      "loss": 0.1447,
      "step": 1260
    },
    {
      "epoch": 3.3866666666666667,
      "grad_norm": 0.059296347200870514,
      "learning_rate": 0.00035177304964539006,
      "loss": 0.1221,
      "step": 1270
    },
    {
      "epoch": 3.413333333333333,
      "grad_norm": 1.666407823562622,
      "learning_rate": 0.00035035460992907804,
      "loss": 0.2286,
      "step": 1280
    },
    {
      "epoch": 3.44,
      "grad_norm": 7.190270900726318,
      "learning_rate": 0.00034893617021276597,
      "loss": 0.1577,
      "step": 1290
    },
    {
      "epoch": 3.466666666666667,
      "grad_norm": 0.04608343914151192,
      "learning_rate": 0.0003475177304964539,
      "loss": 0.1562,
      "step": 1300
    },
    {
      "epoch": 3.493333333333333,
      "grad_norm": 0.08816585689783096,
      "learning_rate": 0.0003460992907801419,
      "loss": 0.1438,
      "step": 1310
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.496241807937622,
      "learning_rate": 0.0003446808510638298,
      "loss": 0.1776,
      "step": 1320
    },
    {
      "epoch": 3.546666666666667,
      "grad_norm": 6.983689785003662,
      "learning_rate": 0.00034326241134751773,
      "loss": 0.1838,
      "step": 1330
    },
    {
      "epoch": 3.5733333333333333,
      "grad_norm": 0.2525334358215332,
      "learning_rate": 0.00034184397163120565,
      "loss": 0.1816,
      "step": 1340
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.05740104615688324,
      "learning_rate": 0.00034042553191489364,
      "loss": 0.1399,
      "step": 1350
    },
    {
      "epoch": 3.626666666666667,
      "grad_norm": 0.09137597680091858,
      "learning_rate": 0.00033900709219858156,
      "loss": 0.2001,
      "step": 1360
    },
    {
      "epoch": 3.6533333333333333,
      "grad_norm": 0.6145536303520203,
      "learning_rate": 0.0003375886524822695,
      "loss": 0.127,
      "step": 1370
    },
    {
      "epoch": 3.68,
      "grad_norm": 7.023932933807373,
      "learning_rate": 0.0003361702127659574,
      "loss": 0.1653,
      "step": 1380
    },
    {
      "epoch": 3.7066666666666666,
      "grad_norm": 0.022993316873908043,
      "learning_rate": 0.0003347517730496454,
      "loss": 0.1618,
      "step": 1390
    },
    {
      "epoch": 3.7333333333333334,
      "grad_norm": 0.36191537976264954,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.1776,
      "step": 1400
    },
    {
      "epoch": 3.76,
      "grad_norm": 9.079767227172852,
      "learning_rate": 0.00033191489361702125,
      "loss": 0.1699,
      "step": 1410
    },
    {
      "epoch": 3.7866666666666666,
      "grad_norm": 0.22280454635620117,
      "learning_rate": 0.00033049645390070923,
      "loss": 0.2018,
      "step": 1420
    },
    {
      "epoch": 3.8133333333333335,
      "grad_norm": 10.14638900756836,
      "learning_rate": 0.00032907801418439716,
      "loss": 0.1815,
      "step": 1430
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.04696489870548248,
      "learning_rate": 0.0003276595744680851,
      "loss": 0.2137,
      "step": 1440
    },
    {
      "epoch": 3.8666666666666667,
      "grad_norm": 0.056405358016490936,
      "learning_rate": 0.00032624113475177306,
      "loss": 0.1716,
      "step": 1450
    },
    {
      "epoch": 3.8933333333333335,
      "grad_norm": 8.17982292175293,
      "learning_rate": 0.00032482269503546104,
      "loss": 0.1735,
      "step": 1460
    },
    {
      "epoch": 3.92,
      "grad_norm": 7.79447078704834,
      "learning_rate": 0.00032340425531914897,
      "loss": 0.1707,
      "step": 1470
    },
    {
      "epoch": 3.9466666666666668,
      "grad_norm": 0.412143737077713,
      "learning_rate": 0.0003219858156028369,
      "loss": 0.1239,
      "step": 1480
    },
    {
      "epoch": 3.9733333333333336,
      "grad_norm": 10.905984878540039,
      "learning_rate": 0.0003205673758865248,
      "loss": 0.165,
      "step": 1490
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.1913708448410034,
      "learning_rate": 0.0003191489361702128,
      "loss": 0.1988,
      "step": 1500
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9645,
      "eval_f1": 0.9640870005058169,
      "eval_loss": 0.20545563101768494,
      "eval_precision": 0.9754350051177073,
      "eval_recall": 0.953,
      "eval_runtime": 3.2816,
      "eval_samples_per_second": 609.46,
      "eval_steps_per_second": 38.091,
      "step": 1500
    },
    {
      "epoch": 4.026666666666666,
      "grad_norm": 5.3889265060424805,
      "learning_rate": 0.00031773049645390073,
      "loss": 0.1636,
      "step": 1510
    },
    {
      "epoch": 4.053333333333334,
      "grad_norm": 0.548208475112915,
      "learning_rate": 0.00031631205673758866,
      "loss": 0.1638,
      "step": 1520
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.28792256116867065,
      "learning_rate": 0.00031489361702127664,
      "loss": 0.1396,
      "step": 1530
    },
    {
      "epoch": 4.1066666666666665,
      "grad_norm": 0.04389788955450058,
      "learning_rate": 0.00031347517730496456,
      "loss": 0.1184,
      "step": 1540
    },
    {
      "epoch": 4.133333333333334,
      "grad_norm": 0.03739814832806587,
      "learning_rate": 0.0003120567375886525,
      "loss": 0.149,
      "step": 1550
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.09661172330379486,
      "learning_rate": 0.0003106382978723404,
      "loss": 0.1594,
      "step": 1560
    },
    {
      "epoch": 4.1866666666666665,
      "grad_norm": 4.021740913391113,
      "learning_rate": 0.0003092198581560284,
      "loss": 0.192,
      "step": 1570
    },
    {
      "epoch": 4.213333333333333,
      "grad_norm": 0.17197713255882263,
      "learning_rate": 0.0003078014184397163,
      "loss": 0.1197,
      "step": 1580
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.1852184683084488,
      "learning_rate": 0.00030638297872340425,
      "loss": 0.1183,
      "step": 1590
    },
    {
      "epoch": 4.266666666666667,
      "grad_norm": 0.10217040032148361,
      "learning_rate": 0.0003049645390070922,
      "loss": 0.1178,
      "step": 1600
    },
    {
      "epoch": 4.293333333333333,
      "grad_norm": 23.108016967773438,
      "learning_rate": 0.00030354609929078016,
      "loss": 0.1449,
      "step": 1610
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.01491035521030426,
      "learning_rate": 0.0003021276595744681,
      "loss": 0.1261,
      "step": 1620
    },
    {
      "epoch": 4.346666666666667,
      "grad_norm": 0.07328842580318451,
      "learning_rate": 0.000300709219858156,
      "loss": 0.1647,
      "step": 1630
    },
    {
      "epoch": 4.373333333333333,
      "grad_norm": 0.3490566909313202,
      "learning_rate": 0.000299290780141844,
      "loss": 0.1409,
      "step": 1640
    },
    {
      "epoch": 4.4,
      "grad_norm": 10.781002044677734,
      "learning_rate": 0.0002978723404255319,
      "loss": 0.1363,
      "step": 1650
    },
    {
      "epoch": 4.426666666666667,
      "grad_norm": 0.02904636785387993,
      "learning_rate": 0.00029645390070921984,
      "loss": 0.1652,
      "step": 1660
    },
    {
      "epoch": 4.453333333333333,
      "grad_norm": 1.382267951965332,
      "learning_rate": 0.00029503546099290777,
      "loss": 0.2173,
      "step": 1670
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.1150713786482811,
      "learning_rate": 0.00029361702127659575,
      "loss": 0.15,
      "step": 1680
    },
    {
      "epoch": 4.506666666666667,
      "grad_norm": 0.09514250606298447,
      "learning_rate": 0.0002921985815602837,
      "loss": 0.1344,
      "step": 1690
    },
    {
      "epoch": 4.533333333333333,
      "grad_norm": 0.34295621514320374,
      "learning_rate": 0.0002907801418439716,
      "loss": 0.1423,
      "step": 1700
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.06393977999687195,
      "learning_rate": 0.00028936170212765953,
      "loss": 0.1435,
      "step": 1710
    },
    {
      "epoch": 4.586666666666667,
      "grad_norm": 5.7712249755859375,
      "learning_rate": 0.00028794326241134757,
      "loss": 0.1205,
      "step": 1720
    },
    {
      "epoch": 4.613333333333333,
      "grad_norm": 2.0644657611846924,
      "learning_rate": 0.0002865248226950355,
      "loss": 0.1404,
      "step": 1730
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.015551233664155006,
      "learning_rate": 0.0002851063829787234,
      "loss": 0.1286,
      "step": 1740
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 0.04969516396522522,
      "learning_rate": 0.0002836879432624114,
      "loss": 0.152,
      "step": 1750
    },
    {
      "epoch": 4.693333333333333,
      "grad_norm": 0.38570138812065125,
      "learning_rate": 0.0002822695035460993,
      "loss": 0.1792,
      "step": 1760
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.11590046435594559,
      "learning_rate": 0.00028085106382978725,
      "loss": 0.1222,
      "step": 1770
    },
    {
      "epoch": 4.746666666666667,
      "grad_norm": 0.038542523980140686,
      "learning_rate": 0.0002794326241134752,
      "loss": 0.1213,
      "step": 1780
    },
    {
      "epoch": 4.773333333333333,
      "grad_norm": 0.30638763308525085,
      "learning_rate": 0.00027801418439716316,
      "loss": 0.1395,
      "step": 1790
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.1108245998620987,
      "learning_rate": 0.0002765957446808511,
      "loss": 0.1323,
      "step": 1800
    },
    {
      "epoch": 4.826666666666666,
      "grad_norm": 0.028085792437195778,
      "learning_rate": 0.000275177304964539,
      "loss": 0.1267,
      "step": 1810
    },
    {
      "epoch": 4.8533333333333335,
      "grad_norm": 0.32683688402175903,
      "learning_rate": 0.00027375886524822694,
      "loss": 0.1862,
      "step": 1820
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.8474106788635254,
      "learning_rate": 0.0002723404255319149,
      "loss": 0.1565,
      "step": 1830
    },
    {
      "epoch": 4.906666666666666,
      "grad_norm": 0.16159114241600037,
      "learning_rate": 0.00027092198581560285,
      "loss": 0.1235,
      "step": 1840
    },
    {
      "epoch": 4.933333333333334,
      "grad_norm": 0.05729631334543228,
      "learning_rate": 0.00026950354609929077,
      "loss": 0.1435,
      "step": 1850
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.04269907996058464,
      "learning_rate": 0.00026808510638297875,
      "loss": 0.1513,
      "step": 1860
    },
    {
      "epoch": 4.986666666666666,
      "grad_norm": 5.124558925628662,
      "learning_rate": 0.0002666666666666667,
      "loss": 0.119,
      "step": 1870
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9715,
      "eval_f1": 0.9713998996487707,
      "eval_loss": 0.19497109949588776,
      "eval_precision": 0.9748237663645518,
      "eval_recall": 0.968,
      "eval_runtime": 3.2965,
      "eval_samples_per_second": 606.702,
      "eval_steps_per_second": 37.919,
      "step": 1875
    },
    {
      "epoch": 5.013333333333334,
      "grad_norm": 0.08178527653217316,
      "learning_rate": 0.0002652482269503546,
      "loss": 0.154,
      "step": 1880
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.04650101438164711,
      "learning_rate": 0.00026382978723404253,
      "loss": 0.118,
      "step": 1890
    },
    {
      "epoch": 5.066666666666666,
      "grad_norm": 0.09010686725378036,
      "learning_rate": 0.0002624113475177305,
      "loss": 0.1174,
      "step": 1900
    },
    {
      "epoch": 5.093333333333334,
      "grad_norm": 0.047516096383333206,
      "learning_rate": 0.00026099290780141844,
      "loss": 0.1617,
      "step": 1910
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.17129352688789368,
      "learning_rate": 0.00025957446808510637,
      "loss": 0.1353,
      "step": 1920
    },
    {
      "epoch": 5.1466666666666665,
      "grad_norm": 0.02168135717511177,
      "learning_rate": 0.0002581560283687943,
      "loss": 0.1186,
      "step": 1930
    },
    {
      "epoch": 5.173333333333334,
      "grad_norm": 0.2840951085090637,
      "learning_rate": 0.0002567375886524823,
      "loss": 0.1417,
      "step": 1940
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.0413275770843029,
      "learning_rate": 0.0002553191489361702,
      "loss": 0.1176,
      "step": 1950
    },
    {
      "epoch": 5.226666666666667,
      "grad_norm": 0.11823758482933044,
      "learning_rate": 0.0002539007092198581,
      "loss": 0.1382,
      "step": 1960
    },
    {
      "epoch": 5.253333333333333,
      "grad_norm": 0.027971677482128143,
      "learning_rate": 0.0002524822695035461,
      "loss": 0.1313,
      "step": 1970
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.02573707327246666,
      "learning_rate": 0.00025106382978723403,
      "loss": 0.143,
      "step": 1980
    },
    {
      "epoch": 5.306666666666667,
      "grad_norm": 0.08540879935026169,
      "learning_rate": 0.000249645390070922,
      "loss": 0.1675,
      "step": 1990
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 1.3159090280532837,
      "learning_rate": 0.00024822695035460994,
      "loss": 0.1404,
      "step": 2000
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.03243087977170944,
      "learning_rate": 0.00024680851063829787,
      "loss": 0.1297,
      "step": 2010
    },
    {
      "epoch": 5.386666666666667,
      "grad_norm": 0.09250327944755554,
      "learning_rate": 0.0002453900709219858,
      "loss": 0.1181,
      "step": 2020
    },
    {
      "epoch": 5.413333333333333,
      "grad_norm": 0.04217595234513283,
      "learning_rate": 0.00024397163120567375,
      "loss": 0.2121,
      "step": 2030
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.25670528411865234,
      "learning_rate": 0.0002425531914893617,
      "loss": 0.14,
      "step": 2040
    },
    {
      "epoch": 5.466666666666667,
      "grad_norm": 0.17182821035385132,
      "learning_rate": 0.00024113475177304963,
      "loss": 0.1938,
      "step": 2050
    },
    {
      "epoch": 5.493333333333333,
      "grad_norm": 0.4051707983016968,
      "learning_rate": 0.0002397163120567376,
      "loss": 0.1264,
      "step": 2060
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.19504979252815247,
      "learning_rate": 0.00023829787234042556,
      "loss": 0.1185,
      "step": 2070
    },
    {
      "epoch": 5.546666666666667,
      "grad_norm": 0.1051492840051651,
      "learning_rate": 0.0002368794326241135,
      "loss": 0.158,
      "step": 2080
    },
    {
      "epoch": 5.573333333333333,
      "grad_norm": 0.03532225638628006,
      "learning_rate": 0.00023546099290780144,
      "loss": 0.118,
      "step": 2090
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.018886413425207138,
      "learning_rate": 0.00023404255319148937,
      "loss": 0.1177,
      "step": 2100
    },
    {
      "epoch": 5.626666666666667,
      "grad_norm": 0.03163212165236473,
      "learning_rate": 0.00023262411347517732,
      "loss": 0.1293,
      "step": 2110
    },
    {
      "epoch": 5.653333333333333,
      "grad_norm": 0.04074708744883537,
      "learning_rate": 0.00023120567375886525,
      "loss": 0.1455,
      "step": 2120
    },
    {
      "epoch": 5.68,
      "grad_norm": 1.138366937637329,
      "learning_rate": 0.0002297872340425532,
      "loss": 0.1882,
      "step": 2130
    },
    {
      "epoch": 5.706666666666667,
      "grad_norm": 2.802957057952881,
      "learning_rate": 0.00022836879432624113,
      "loss": 0.1448,
      "step": 2140
    },
    {
      "epoch": 5.733333333333333,
      "grad_norm": 0.04233120009303093,
      "learning_rate": 0.00022695035460992908,
      "loss": 0.1192,
      "step": 2150
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.04263363778591156,
      "learning_rate": 0.000225531914893617,
      "loss": 0.1337,
      "step": 2160
    },
    {
      "epoch": 5.786666666666667,
      "grad_norm": 0.038348644971847534,
      "learning_rate": 0.00022411347517730496,
      "loss": 0.1342,
      "step": 2170
    },
    {
      "epoch": 5.8133333333333335,
      "grad_norm": 0.065469890832901,
      "learning_rate": 0.0002226950354609929,
      "loss": 0.1505,
      "step": 2180
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.029752295464277267,
      "learning_rate": 0.00022127659574468084,
      "loss": 0.1302,
      "step": 2190
    },
    {
      "epoch": 5.866666666666667,
      "grad_norm": 0.01853938400745392,
      "learning_rate": 0.00021985815602836882,
      "loss": 0.1351,
      "step": 2200
    },
    {
      "epoch": 5.8933333333333335,
      "grad_norm": 0.026979565620422363,
      "learning_rate": 0.00021843971631205675,
      "loss": 0.1282,
      "step": 2210
    },
    {
      "epoch": 5.92,
      "grad_norm": 4.492976188659668,
      "learning_rate": 0.0002170212765957447,
      "loss": 0.136,
      "step": 2220
    },
    {
      "epoch": 5.946666666666666,
      "grad_norm": 0.014039965346455574,
      "learning_rate": 0.00021560283687943263,
      "loss": 0.1286,
      "step": 2230
    },
    {
      "epoch": 5.973333333333334,
      "grad_norm": 2.917003870010376,
      "learning_rate": 0.00021418439716312058,
      "loss": 0.1559,
      "step": 2240
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.07778198271989822,
      "learning_rate": 0.0002127659574468085,
      "loss": 0.1262,
      "step": 2250
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9625,
      "eval_f1": 0.9617542070372259,
      "eval_loss": 0.22621896862983704,
      "eval_precision": 0.9812695109261186,
      "eval_recall": 0.943,
      "eval_runtime": 3.2821,
      "eval_samples_per_second": 609.364,
      "eval_steps_per_second": 38.085,
      "step": 2250
    },
    {
      "epoch": 6.026666666666666,
      "grad_norm": 0.08809476345777512,
      "learning_rate": 0.00021134751773049646,
      "loss": 0.1596,
      "step": 2260
    },
    {
      "epoch": 6.053333333333334,
      "grad_norm": 0.025839421898126602,
      "learning_rate": 0.0002099290780141844,
      "loss": 0.1172,
      "step": 2270
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.02030041813850403,
      "learning_rate": 0.00020851063829787234,
      "loss": 0.13,
      "step": 2280
    },
    {
      "epoch": 6.1066666666666665,
      "grad_norm": 0.14299103617668152,
      "learning_rate": 0.00020709219858156027,
      "loss": 0.1561,
      "step": 2290
    },
    {
      "epoch": 6.133333333333334,
      "grad_norm": 0.08787886053323746,
      "learning_rate": 0.00020567375886524822,
      "loss": 0.1195,
      "step": 2300
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.01405020710080862,
      "learning_rate": 0.00020425531914893618,
      "loss": 0.1177,
      "step": 2310
    },
    {
      "epoch": 6.1866666666666665,
      "grad_norm": 0.04174847900867462,
      "learning_rate": 0.0002028368794326241,
      "loss": 0.1186,
      "step": 2320
    },
    {
      "epoch": 6.213333333333333,
      "grad_norm": 0.08874887973070145,
      "learning_rate": 0.00020141843971631208,
      "loss": 0.1466,
      "step": 2330
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.039614442735910416,
      "learning_rate": 0.0002,
      "loss": 0.1182,
      "step": 2340
    },
    {
      "epoch": 6.266666666666667,
      "grad_norm": 0.028893230482935905,
      "learning_rate": 0.00019858156028368796,
      "loss": 0.1218,
      "step": 2350
    },
    {
      "epoch": 6.293333333333333,
      "grad_norm": 0.040098775178194046,
      "learning_rate": 0.0001971631205673759,
      "loss": 0.1173,
      "step": 2360
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.041379962116479874,
      "learning_rate": 0.00019574468085106384,
      "loss": 0.1187,
      "step": 2370
    },
    {
      "epoch": 6.346666666666667,
      "grad_norm": 0.008904053829610348,
      "learning_rate": 0.00019432624113475177,
      "loss": 0.1314,
      "step": 2380
    },
    {
      "epoch": 6.373333333333333,
      "grad_norm": 0.02686980925500393,
      "learning_rate": 0.00019290780141843972,
      "loss": 0.1174,
      "step": 2390
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.02094447799026966,
      "learning_rate": 0.00019148936170212765,
      "loss": 0.131,
      "step": 2400
    },
    {
      "epoch": 6.426666666666667,
      "grad_norm": 0.011339214630424976,
      "learning_rate": 0.0001900709219858156,
      "loss": 0.1195,
      "step": 2410
    },
    {
      "epoch": 6.453333333333333,
      "grad_norm": 0.11755849421024323,
      "learning_rate": 0.00018865248226950356,
      "loss": 0.135,
      "step": 2420
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.08509454876184464,
      "learning_rate": 0.00018723404255319148,
      "loss": 0.1177,
      "step": 2430
    },
    {
      "epoch": 6.506666666666667,
      "grad_norm": 0.022594299167394638,
      "learning_rate": 0.00018581560283687944,
      "loss": 0.1545,
      "step": 2440
    },
    {
      "epoch": 6.533333333333333,
      "grad_norm": 0.037704214453697205,
      "learning_rate": 0.00018439716312056736,
      "loss": 0.1193,
      "step": 2450
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.05627324432134628,
      "learning_rate": 0.00018297872340425532,
      "loss": 0.1315,
      "step": 2460
    },
    {
      "epoch": 6.586666666666667,
      "grad_norm": 0.8664852380752563,
      "learning_rate": 0.00018156028368794327,
      "loss": 0.1432,
      "step": 2470
    },
    {
      "epoch": 6.613333333333333,
      "grad_norm": 0.7425404191017151,
      "learning_rate": 0.00018014184397163122,
      "loss": 0.1176,
      "step": 2480
    },
    {
      "epoch": 6.64,
      "grad_norm": 12.577340126037598,
      "learning_rate": 0.00017872340425531915,
      "loss": 0.1745,
      "step": 2490
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.033812981098890305,
      "learning_rate": 0.0001773049645390071,
      "loss": 0.1384,
      "step": 2500
    },
    {
      "epoch": 6.693333333333333,
      "grad_norm": 7.370875835418701,
      "learning_rate": 0.00017588652482269503,
      "loss": 0.1377,
      "step": 2510
    },
    {
      "epoch": 6.72,
      "grad_norm": 4.146276950836182,
      "learning_rate": 0.00017446808510638298,
      "loss": 0.154,
      "step": 2520
    },
    {
      "epoch": 6.746666666666667,
      "grad_norm": 1.006230354309082,
      "learning_rate": 0.00017304964539007094,
      "loss": 0.1185,
      "step": 2530
    },
    {
      "epoch": 6.773333333333333,
      "grad_norm": 14.161144256591797,
      "learning_rate": 0.00017163120567375886,
      "loss": 0.1404,
      "step": 2540
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.16307291388511658,
      "learning_rate": 0.00017021276595744682,
      "loss": 0.1407,
      "step": 2550
    },
    {
      "epoch": 6.826666666666666,
      "grad_norm": 0.04590612277388573,
      "learning_rate": 0.00016879432624113474,
      "loss": 0.135,
      "step": 2560
    },
    {
      "epoch": 6.8533333333333335,
      "grad_norm": 0.0300570260733366,
      "learning_rate": 0.0001673758865248227,
      "loss": 0.1176,
      "step": 2570
    },
    {
      "epoch": 6.88,
      "grad_norm": 1.8105506896972656,
      "learning_rate": 0.00016595744680851062,
      "loss": 0.1496,
      "step": 2580
    },
    {
      "epoch": 6.906666666666666,
      "grad_norm": 0.020863711833953857,
      "learning_rate": 0.00016453900709219858,
      "loss": 0.118,
      "step": 2590
    },
    {
      "epoch": 6.933333333333334,
      "grad_norm": 0.03442356735467911,
      "learning_rate": 0.00016312056737588653,
      "loss": 0.1351,
      "step": 2600
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.014935008250176907,
      "learning_rate": 0.00016170212765957449,
      "loss": 0.1398,
      "step": 2610
    },
    {
      "epoch": 6.986666666666666,
      "grad_norm": 7.33126974105835,
      "learning_rate": 0.0001602836879432624,
      "loss": 0.2071,
      "step": 2620
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.971,
      "eval_f1": 0.971201588877855,
      "eval_loss": 0.1945614069700241,
      "eval_precision": 0.9644970414201184,
      "eval_recall": 0.978,
      "eval_runtime": 3.2745,
      "eval_samples_per_second": 610.783,
      "eval_steps_per_second": 38.174,
      "step": 2625
    },
    {
      "epoch": 7.013333333333334,
      "grad_norm": 0.07618630677461624,
      "learning_rate": 0.00015886524822695037,
      "loss": 0.119,
      "step": 2630
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.473713755607605,
      "learning_rate": 0.00015744680851063832,
      "loss": 0.1358,
      "step": 2640
    },
    {
      "epoch": 7.066666666666666,
      "grad_norm": 0.20634378492832184,
      "learning_rate": 0.00015602836879432625,
      "loss": 0.119,
      "step": 2650
    },
    {
      "epoch": 7.093333333333334,
      "grad_norm": 0.05383245274424553,
      "learning_rate": 0.0001546099290780142,
      "loss": 0.1175,
      "step": 2660
    },
    {
      "epoch": 7.12,
      "grad_norm": 0.046502627432346344,
      "learning_rate": 0.00015319148936170213,
      "loss": 0.1506,
      "step": 2670
    },
    {
      "epoch": 7.1466666666666665,
      "grad_norm": 0.07431881129741669,
      "learning_rate": 0.00015177304964539008,
      "loss": 0.123,
      "step": 2680
    },
    {
      "epoch": 7.173333333333334,
      "grad_norm": 0.5092447400093079,
      "learning_rate": 0.000150354609929078,
      "loss": 0.1478,
      "step": 2690
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.04513969272375107,
      "learning_rate": 0.00014893617021276596,
      "loss": 0.1174,
      "step": 2700
    },
    {
      "epoch": 7.226666666666667,
      "grad_norm": 1.4708166122436523,
      "learning_rate": 0.00014751773049645389,
      "loss": 0.1179,
      "step": 2710
    },
    {
      "epoch": 7.253333333333333,
      "grad_norm": 0.05631769448518753,
      "learning_rate": 0.00014609929078014184,
      "loss": 0.1379,
      "step": 2720
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.030554136261343956,
      "learning_rate": 0.00014468085106382977,
      "loss": 0.1205,
      "step": 2730
    },
    {
      "epoch": 7.306666666666667,
      "grad_norm": 0.01957358606159687,
      "learning_rate": 0.00014326241134751775,
      "loss": 0.1175,
      "step": 2740
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 0.026499327272176743,
      "learning_rate": 0.0001418439716312057,
      "loss": 0.1173,
      "step": 2750
    },
    {
      "epoch": 7.36,
      "grad_norm": 0.013131377287209034,
      "learning_rate": 0.00014042553191489363,
      "loss": 0.1173,
      "step": 2760
    },
    {
      "epoch": 7.386666666666667,
      "grad_norm": 0.026586974039673805,
      "learning_rate": 0.00013900709219858158,
      "loss": 0.118,
      "step": 2770
    },
    {
      "epoch": 7.413333333333333,
      "grad_norm": 0.018073536455631256,
      "learning_rate": 0.0001375886524822695,
      "loss": 0.1334,
      "step": 2780
    },
    {
      "epoch": 7.44,
      "grad_norm": 12.20869255065918,
      "learning_rate": 0.00013617021276595746,
      "loss": 0.1234,
      "step": 2790
    },
    {
      "epoch": 7.466666666666667,
      "grad_norm": 0.04110584035515785,
      "learning_rate": 0.00013475177304964539,
      "loss": 0.137,
      "step": 2800
    },
    {
      "epoch": 7.493333333333333,
      "grad_norm": 0.041797373443841934,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.1189,
      "step": 2810
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.015975963324308395,
      "learning_rate": 0.00013191489361702127,
      "loss": 0.1382,
      "step": 2820
    },
    {
      "epoch": 7.546666666666667,
      "grad_norm": 0.0171514879912138,
      "learning_rate": 0.00013049645390070922,
      "loss": 0.1172,
      "step": 2830
    },
    {
      "epoch": 7.573333333333333,
      "grad_norm": 0.017101507633924484,
      "learning_rate": 0.00012907801418439715,
      "loss": 0.1179,
      "step": 2840
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.015040158294141293,
      "learning_rate": 0.0001276595744680851,
      "loss": 0.1201,
      "step": 2850
    },
    {
      "epoch": 7.626666666666667,
      "grad_norm": 0.01423072349280119,
      "learning_rate": 0.00012624113475177305,
      "loss": 0.1173,
      "step": 2860
    },
    {
      "epoch": 7.653333333333333,
      "grad_norm": 0.02258501760661602,
      "learning_rate": 0.000124822695035461,
      "loss": 0.1179,
      "step": 2870
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.02767682448029518,
      "learning_rate": 0.00012340425531914893,
      "loss": 0.1195,
      "step": 2880
    },
    {
      "epoch": 7.706666666666667,
      "grad_norm": 0.10689529776573181,
      "learning_rate": 0.00012198581560283687,
      "loss": 0.1175,
      "step": 2890
    },
    {
      "epoch": 7.733333333333333,
      "grad_norm": 0.0175448227673769,
      "learning_rate": 0.00012056737588652481,
      "loss": 0.1174,
      "step": 2900
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.030141498893499374,
      "learning_rate": 0.00011914893617021278,
      "loss": 0.1203,
      "step": 2910
    },
    {
      "epoch": 7.786666666666667,
      "grad_norm": 0.011076507158577442,
      "learning_rate": 0.00011773049645390072,
      "loss": 0.1345,
      "step": 2920
    },
    {
      "epoch": 7.8133333333333335,
      "grad_norm": 3.0164313316345215,
      "learning_rate": 0.00011631205673758866,
      "loss": 0.134,
      "step": 2930
    },
    {
      "epoch": 7.84,
      "grad_norm": 13.223206520080566,
      "learning_rate": 0.0001148936170212766,
      "loss": 0.1503,
      "step": 2940
    },
    {
      "epoch": 7.866666666666667,
      "grad_norm": 0.15326757729053497,
      "learning_rate": 0.00011347517730496454,
      "loss": 0.1173,
      "step": 2950
    },
    {
      "epoch": 7.8933333333333335,
      "grad_norm": 0.023393305018544197,
      "learning_rate": 0.00011205673758865248,
      "loss": 0.1299,
      "step": 2960
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.026135189458727837,
      "learning_rate": 0.00011063829787234042,
      "loss": 0.1189,
      "step": 2970
    },
    {
      "epoch": 7.946666666666666,
      "grad_norm": 0.044251251965761185,
      "learning_rate": 0.00010921985815602837,
      "loss": 0.1454,
      "step": 2980
    },
    {
      "epoch": 7.973333333333334,
      "grad_norm": 0.011535227298736572,
      "learning_rate": 0.00010780141843971631,
      "loss": 0.1175,
      "step": 2990
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.04243878275156021,
      "learning_rate": 0.00010638297872340425,
      "loss": 0.1181,
      "step": 3000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.97,
      "eval_f1": 0.97002997002997,
      "eval_loss": 0.20847629010677338,
      "eval_precision": 0.969061876247505,
      "eval_recall": 0.971,
      "eval_runtime": 3.2767,
      "eval_samples_per_second": 610.367,
      "eval_steps_per_second": 38.148,
      "step": 3000
    },
    {
      "epoch": 8.026666666666667,
      "grad_norm": 0.005965540651232004,
      "learning_rate": 0.0001049645390070922,
      "loss": 0.1173,
      "step": 3010
    },
    {
      "epoch": 8.053333333333333,
      "grad_norm": 0.00863067526370287,
      "learning_rate": 0.00010354609929078013,
      "loss": 0.1226,
      "step": 3020
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.28228721022605896,
      "learning_rate": 0.00010212765957446809,
      "loss": 0.1173,
      "step": 3030
    },
    {
      "epoch": 8.106666666666667,
      "grad_norm": 0.011806140653789043,
      "learning_rate": 0.00010070921985815604,
      "loss": 0.1375,
      "step": 3040
    },
    {
      "epoch": 8.133333333333333,
      "grad_norm": 0.010786930099129677,
      "learning_rate": 9.929078014184398e-05,
      "loss": 0.1173,
      "step": 3050
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.1778669357299805,
      "learning_rate": 9.787234042553192e-05,
      "loss": 0.1376,
      "step": 3060
    },
    {
      "epoch": 8.186666666666667,
      "grad_norm": 0.06533233076334,
      "learning_rate": 9.645390070921986e-05,
      "loss": 0.1174,
      "step": 3070
    },
    {
      "epoch": 8.213333333333333,
      "grad_norm": 0.07562680542469025,
      "learning_rate": 9.50354609929078e-05,
      "loss": 0.1368,
      "step": 3080
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.0260445736348629,
      "learning_rate": 9.361702127659574e-05,
      "loss": 0.1182,
      "step": 3090
    },
    {
      "epoch": 8.266666666666667,
      "grad_norm": 0.053793370723724365,
      "learning_rate": 9.219858156028368e-05,
      "loss": 0.1172,
      "step": 3100
    },
    {
      "epoch": 8.293333333333333,
      "grad_norm": 0.1683456301689148,
      "learning_rate": 9.078014184397164e-05,
      "loss": 0.1478,
      "step": 3110
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.1048980951309204,
      "learning_rate": 8.936170212765958e-05,
      "loss": 0.1396,
      "step": 3120
    },
    {
      "epoch": 8.346666666666668,
      "grad_norm": 0.018361283466219902,
      "learning_rate": 8.794326241134752e-05,
      "loss": 0.1173,
      "step": 3130
    },
    {
      "epoch": 8.373333333333333,
      "grad_norm": 0.08381475508213043,
      "learning_rate": 8.652482269503547e-05,
      "loss": 0.1356,
      "step": 3140
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.06683965772390366,
      "learning_rate": 8.510638297872341e-05,
      "loss": 0.1393,
      "step": 3150
    },
    {
      "epoch": 8.426666666666666,
      "grad_norm": 0.07598870992660522,
      "learning_rate": 8.368794326241135e-05,
      "loss": 0.1181,
      "step": 3160
    },
    {
      "epoch": 8.453333333333333,
      "grad_norm": 0.01801275461912155,
      "learning_rate": 8.226950354609929e-05,
      "loss": 0.1176,
      "step": 3170
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.02727189101278782,
      "learning_rate": 8.085106382978724e-05,
      "loss": 0.1172,
      "step": 3180
    },
    {
      "epoch": 8.506666666666666,
      "grad_norm": 0.02322300523519516,
      "learning_rate": 7.943262411347518e-05,
      "loss": 0.1559,
      "step": 3190
    },
    {
      "epoch": 8.533333333333333,
      "grad_norm": 0.0130491703748703,
      "learning_rate": 7.801418439716312e-05,
      "loss": 0.1179,
      "step": 3200
    },
    {
      "epoch": 8.56,
      "grad_norm": 0.046697430312633514,
      "learning_rate": 7.659574468085106e-05,
      "loss": 0.1606,
      "step": 3210
    },
    {
      "epoch": 8.586666666666666,
      "grad_norm": 0.038201913237571716,
      "learning_rate": 7.5177304964539e-05,
      "loss": 0.1282,
      "step": 3220
    },
    {
      "epoch": 8.613333333333333,
      "grad_norm": 7.856958866119385,
      "learning_rate": 7.375886524822694e-05,
      "loss": 0.1349,
      "step": 3230
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.029751475900411606,
      "learning_rate": 7.234042553191488e-05,
      "loss": 0.1196,
      "step": 3240
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 0.017177389934659004,
      "learning_rate": 7.092198581560285e-05,
      "loss": 0.1357,
      "step": 3250
    },
    {
      "epoch": 8.693333333333333,
      "grad_norm": 0.01107260026037693,
      "learning_rate": 6.950354609929079e-05,
      "loss": 0.1415,
      "step": 3260
    },
    {
      "epoch": 8.72,
      "grad_norm": 0.04046666994690895,
      "learning_rate": 6.808510638297873e-05,
      "loss": 0.1377,
      "step": 3270
    },
    {
      "epoch": 8.746666666666666,
      "grad_norm": 0.0633009746670723,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.1175,
      "step": 3280
    },
    {
      "epoch": 8.773333333333333,
      "grad_norm": 0.036594685167074203,
      "learning_rate": 6.524822695035461e-05,
      "loss": 0.1326,
      "step": 3290
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.016396118327975273,
      "learning_rate": 6.382978723404255e-05,
      "loss": 0.1174,
      "step": 3300
    },
    {
      "epoch": 8.826666666666666,
      "grad_norm": 0.07819149643182755,
      "learning_rate": 6.24113475177305e-05,
      "loss": 0.1182,
      "step": 3310
    },
    {
      "epoch": 8.853333333333333,
      "grad_norm": 0.16710028052330017,
      "learning_rate": 6.099290780141844e-05,
      "loss": 0.1172,
      "step": 3320
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.014444896019995213,
      "learning_rate": 5.957446808510639e-05,
      "loss": 0.1173,
      "step": 3330
    },
    {
      "epoch": 8.906666666666666,
      "grad_norm": 0.026127293705940247,
      "learning_rate": 5.815602836879433e-05,
      "loss": 0.1172,
      "step": 3340
    },
    {
      "epoch": 8.933333333333334,
      "grad_norm": 0.022405683994293213,
      "learning_rate": 5.673758865248227e-05,
      "loss": 0.1383,
      "step": 3350
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.0324680432677269,
      "learning_rate": 5.531914893617021e-05,
      "loss": 0.1173,
      "step": 3360
    },
    {
      "epoch": 8.986666666666666,
      "grad_norm": 0.05891910195350647,
      "learning_rate": 5.390070921985816e-05,
      "loss": 0.1288,
      "step": 3370
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9705,
      "eval_f1": 0.9705735660847881,
      "eval_loss": 0.20448949933052063,
      "eval_precision": 0.9681592039800995,
      "eval_recall": 0.973,
      "eval_runtime": 3.3017,
      "eval_samples_per_second": 605.746,
      "eval_steps_per_second": 37.859,
      "step": 3375
    }
  ],
  "logging_steps": 10,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1633395522627840.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
