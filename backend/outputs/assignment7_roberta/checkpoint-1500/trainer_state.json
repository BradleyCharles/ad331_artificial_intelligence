{
  "best_metric": 0.972,
  "best_model_checkpoint": "outputs/assignment7_roberta/checkpoint-1125",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 1.3340190649032593,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.7007,
      "step": 10
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.8752999901771545,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.6865,
      "step": 20
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.4065897464752197,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.6954,
      "step": 30
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 2.6209194660186768,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.6902,
      "step": 40
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.4127751588821411,
      "learning_rate": 0.0001111111111111111,
      "loss": 0.6439,
      "step": 50
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.274609088897705,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.4483,
      "step": 60
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 9.437146186828613,
      "learning_rate": 0.00015555555555555556,
      "loss": 0.433,
      "step": 70
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 8.802699089050293,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.2819,
      "step": 80
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.737595558166504,
      "learning_rate": 0.0002,
      "loss": 0.3217,
      "step": 90
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 3.020366907119751,
      "learning_rate": 0.0002222222222222222,
      "loss": 0.3438,
      "step": 100
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 6.522631645202637,
      "learning_rate": 0.00024444444444444443,
      "loss": 0.444,
      "step": 110
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.37520170211792,
      "learning_rate": 0.0002666666666666667,
      "loss": 0.3375,
      "step": 120
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 2.440840244293213,
      "learning_rate": 0.0002888888888888889,
      "loss": 0.2963,
      "step": 130
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 4.665585517883301,
      "learning_rate": 0.0003111111111111111,
      "loss": 0.2949,
      "step": 140
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5990480780601501,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.3042,
      "step": 150
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 4.109732151031494,
      "learning_rate": 0.00035555555555555557,
      "loss": 0.3441,
      "step": 160
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 1.9060498476028442,
      "learning_rate": 0.00037777777777777777,
      "loss": 0.324,
      "step": 170
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.2894931733608246,
      "learning_rate": 0.0004,
      "loss": 0.3104,
      "step": 180
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 1.1362206935882568,
      "learning_rate": 0.0004222222222222222,
      "loss": 0.2622,
      "step": 190
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 4.588229179382324,
      "learning_rate": 0.0004444444444444444,
      "loss": 0.2841,
      "step": 200
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.632187843322754,
      "learning_rate": 0.00046666666666666666,
      "loss": 0.2526,
      "step": 210
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 1.7339062690734863,
      "learning_rate": 0.0004888888888888889,
      "loss": 0.2429,
      "step": 220
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 1.8498952388763428,
      "learning_rate": 0.000499290780141844,
      "loss": 0.2861,
      "step": 230
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.4377846717834473,
      "learning_rate": 0.000497872340425532,
      "loss": 0.2272,
      "step": 240
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 5.9854278564453125,
      "learning_rate": 0.0004964539007092199,
      "loss": 0.2917,
      "step": 250
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 1.3027735948562622,
      "learning_rate": 0.0004950354609929078,
      "loss": 0.3133,
      "step": 260
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0105628967285156,
      "learning_rate": 0.0004936170212765957,
      "loss": 0.2973,
      "step": 270
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 1.355081558227539,
      "learning_rate": 0.0004921985815602837,
      "loss": 0.2032,
      "step": 280
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 1.6863762140274048,
      "learning_rate": 0.0004907801418439716,
      "loss": 0.1674,
      "step": 290
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.8702752590179443,
      "learning_rate": 0.0004893617021276596,
      "loss": 0.348,
      "step": 300
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 4.027673721313477,
      "learning_rate": 0.0004879432624113475,
      "loss": 0.2716,
      "step": 310
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.19163314998149872,
      "learning_rate": 0.0004865248226950355,
      "loss": 0.2113,
      "step": 320
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0682876110076904,
      "learning_rate": 0.0004851063829787234,
      "loss": 0.2816,
      "step": 330
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 2.6967527866363525,
      "learning_rate": 0.00048368794326241133,
      "loss": 0.2354,
      "step": 340
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 1.0981802940368652,
      "learning_rate": 0.00048226950354609925,
      "loss": 0.3244,
      "step": 350
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.7437596321105957,
      "learning_rate": 0.00048085106382978723,
      "loss": 0.2161,
      "step": 360
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.361149400472641,
      "learning_rate": 0.0004794326241134752,
      "loss": 0.2238,
      "step": 370
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9515,
      "eval_f1": 0.9532530120481928,
      "eval_loss": 0.22705689072608948,
      "eval_precision": 0.92,
      "eval_recall": 0.989,
      "eval_runtime": 3.2801,
      "eval_samples_per_second": 609.739,
      "eval_steps_per_second": 38.109,
      "step": 375
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 1.258109211921692,
      "learning_rate": 0.00047801418439716314,
      "loss": 0.3468,
      "step": 380
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.23898841440677643,
      "learning_rate": 0.0004765957446808511,
      "loss": 0.208,
      "step": 390
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.22564582526683807,
      "learning_rate": 0.00047517730496453905,
      "loss": 0.28,
      "step": 400
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 2.3028178215026855,
      "learning_rate": 0.000473758865248227,
      "loss": 0.2147,
      "step": 410
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.71304851770401,
      "learning_rate": 0.0004723404255319149,
      "loss": 0.1938,
      "step": 420
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 1.3308311700820923,
      "learning_rate": 0.0004709219858156029,
      "loss": 0.2077,
      "step": 430
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 1.4345327615737915,
      "learning_rate": 0.0004695035460992908,
      "loss": 0.1868,
      "step": 440
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.036962628364563,
      "learning_rate": 0.00046808510638297874,
      "loss": 0.1858,
      "step": 450
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 6.033728122711182,
      "learning_rate": 0.00046666666666666666,
      "loss": 0.2216,
      "step": 460
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 0.17402128875255585,
      "learning_rate": 0.00046524822695035464,
      "loss": 0.1642,
      "step": 470
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.09791074693202972,
      "learning_rate": 0.00046382978723404257,
      "loss": 0.1392,
      "step": 480
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 1.9078340530395508,
      "learning_rate": 0.0004624113475177305,
      "loss": 0.232,
      "step": 490
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 2.7955615520477295,
      "learning_rate": 0.0004609929078014184,
      "loss": 0.2454,
      "step": 500
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.6578898429870605,
      "learning_rate": 0.0004595744680851064,
      "loss": 0.2331,
      "step": 510
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 6.513657569885254,
      "learning_rate": 0.00045815602836879433,
      "loss": 0.254,
      "step": 520
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 0.6565953493118286,
      "learning_rate": 0.00045673758865248226,
      "loss": 0.2534,
      "step": 530
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.24524948000907898,
      "learning_rate": 0.00045531914893617024,
      "loss": 0.2249,
      "step": 540
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 4.445156574249268,
      "learning_rate": 0.00045390070921985816,
      "loss": 0.2032,
      "step": 550
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 0.1516430824995041,
      "learning_rate": 0.0004524822695035461,
      "loss": 0.1797,
      "step": 560
    },
    {
      "epoch": 1.52,
      "grad_norm": 4.711146831512451,
      "learning_rate": 0.000451063829787234,
      "loss": 0.1371,
      "step": 570
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 0.06213860586285591,
      "learning_rate": 0.000449645390070922,
      "loss": 0.1775,
      "step": 580
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 0.35743001103401184,
      "learning_rate": 0.0004482269503546099,
      "loss": 0.2576,
      "step": 590
    },
    {
      "epoch": 1.6,
      "grad_norm": 5.042155742645264,
      "learning_rate": 0.00044680851063829785,
      "loss": 0.1991,
      "step": 600
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 0.11109598726034164,
      "learning_rate": 0.0004453900709219858,
      "loss": 0.2627,
      "step": 610
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 3.1654577255249023,
      "learning_rate": 0.00044397163120567376,
      "loss": 0.1954,
      "step": 620
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.3886061906814575,
      "learning_rate": 0.0004425531914893617,
      "loss": 0.2256,
      "step": 630
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 2.700378656387329,
      "learning_rate": 0.00044113475177304966,
      "loss": 0.2278,
      "step": 640
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 5.5558905601501465,
      "learning_rate": 0.00043971631205673764,
      "loss": 0.209,
      "step": 650
    },
    {
      "epoch": 1.76,
      "grad_norm": 4.138044834136963,
      "learning_rate": 0.00043829787234042557,
      "loss": 0.196,
      "step": 660
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 1.81257963180542,
      "learning_rate": 0.0004368794326241135,
      "loss": 0.2623,
      "step": 670
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 0.03933197632431984,
      "learning_rate": 0.0004354609929078014,
      "loss": 0.2067,
      "step": 680
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 8.804805755615234,
      "learning_rate": 0.0004340425531914894,
      "loss": 0.2162,
      "step": 690
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 1.9733492136001587,
      "learning_rate": 0.00043262411347517733,
      "loss": 0.2268,
      "step": 700
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 7.750497341156006,
      "learning_rate": 0.00043120567375886526,
      "loss": 0.255,
      "step": 710
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.0321884155273438,
      "learning_rate": 0.0004297872340425532,
      "loss": 0.2717,
      "step": 720
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 1.8373576402664185,
      "learning_rate": 0.00042836879432624116,
      "loss": 0.275,
      "step": 730
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 0.4031604826450348,
      "learning_rate": 0.0004269503546099291,
      "loss": 0.2057,
      "step": 740
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.209178447723389,
      "learning_rate": 0.000425531914893617,
      "loss": 0.1878,
      "step": 750
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9575,
      "eval_f1": 0.9589570255915016,
      "eval_loss": 0.21919968724250793,
      "eval_precision": 0.927170868347339,
      "eval_recall": 0.993,
      "eval_runtime": 3.2947,
      "eval_samples_per_second": 607.039,
      "eval_steps_per_second": 37.94,
      "step": 750
    },
    {
      "epoch": 2.026666666666667,
      "grad_norm": 2.621140718460083,
      "learning_rate": 0.000424113475177305,
      "loss": 0.1647,
      "step": 760
    },
    {
      "epoch": 2.0533333333333332,
      "grad_norm": 1.5493125915527344,
      "learning_rate": 0.0004226950354609929,
      "loss": 0.182,
      "step": 770
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.4318485260009766,
      "learning_rate": 0.00042127659574468085,
      "loss": 0.1751,
      "step": 780
    },
    {
      "epoch": 2.1066666666666665,
      "grad_norm": 1.1306718587875366,
      "learning_rate": 0.0004198581560283688,
      "loss": 0.2107,
      "step": 790
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 1.6332589387893677,
      "learning_rate": 0.00041843971631205676,
      "loss": 0.2038,
      "step": 800
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6397740840911865,
      "learning_rate": 0.0004170212765957447,
      "loss": 0.1722,
      "step": 810
    },
    {
      "epoch": 2.1866666666666665,
      "grad_norm": 0.6995317935943604,
      "learning_rate": 0.0004156028368794326,
      "loss": 0.1401,
      "step": 820
    },
    {
      "epoch": 2.2133333333333334,
      "grad_norm": 1.2786585092544556,
      "learning_rate": 0.00041418439716312054,
      "loss": 0.1939,
      "step": 830
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.10315434634685516,
      "learning_rate": 0.0004127659574468085,
      "loss": 0.1389,
      "step": 840
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 6.685894966125488,
      "learning_rate": 0.00041134751773049644,
      "loss": 0.1675,
      "step": 850
    },
    {
      "epoch": 2.2933333333333334,
      "grad_norm": 0.2867056727409363,
      "learning_rate": 0.00040992907801418437,
      "loss": 0.2045,
      "step": 860
    },
    {
      "epoch": 2.32,
      "grad_norm": 7.7000908851623535,
      "learning_rate": 0.00040851063829787235,
      "loss": 0.1973,
      "step": 870
    },
    {
      "epoch": 2.3466666666666667,
      "grad_norm": 1.7615951299667358,
      "learning_rate": 0.0004070921985815603,
      "loss": 0.1936,
      "step": 880
    },
    {
      "epoch": 2.3733333333333335,
      "grad_norm": 0.08140455186367035,
      "learning_rate": 0.0004056737588652482,
      "loss": 0.1332,
      "step": 890
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.10447713732719421,
      "learning_rate": 0.00040425531914893613,
      "loss": 0.1462,
      "step": 900
    },
    {
      "epoch": 2.4266666666666667,
      "grad_norm": 0.30062195658683777,
      "learning_rate": 0.00040283687943262417,
      "loss": 0.2181,
      "step": 910
    },
    {
      "epoch": 2.453333333333333,
      "grad_norm": 0.18652509152889252,
      "learning_rate": 0.0004014184397163121,
      "loss": 0.2524,
      "step": 920
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.24221442639827728,
      "learning_rate": 0.0004,
      "loss": 0.1989,
      "step": 930
    },
    {
      "epoch": 2.506666666666667,
      "grad_norm": 0.09507117420434952,
      "learning_rate": 0.00039858156028368795,
      "loss": 0.1508,
      "step": 940
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 0.03679557889699936,
      "learning_rate": 0.0003971631205673759,
      "loss": 0.1883,
      "step": 950
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.031266700476408005,
      "learning_rate": 0.00039574468085106385,
      "loss": 0.1406,
      "step": 960
    },
    {
      "epoch": 2.586666666666667,
      "grad_norm": 1.5703192949295044,
      "learning_rate": 0.0003943262411347518,
      "loss": 0.1811,
      "step": 970
    },
    {
      "epoch": 2.6133333333333333,
      "grad_norm": 3.874180555343628,
      "learning_rate": 0.00039290780141843976,
      "loss": 0.1834,
      "step": 980
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.4239379167556763,
      "learning_rate": 0.0003914893617021277,
      "loss": 0.1822,
      "step": 990
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.19986727833747864,
      "learning_rate": 0.0003900709219858156,
      "loss": 0.1972,
      "step": 1000
    },
    {
      "epoch": 2.6933333333333334,
      "grad_norm": 0.2861661911010742,
      "learning_rate": 0.00038865248226950354,
      "loss": 0.1797,
      "step": 1010
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 7.400167465209961,
      "learning_rate": 0.0003872340425531915,
      "loss": 0.1725,
      "step": 1020
    },
    {
      "epoch": 2.7466666666666666,
      "grad_norm": 0.21323654055595398,
      "learning_rate": 0.00038581560283687945,
      "loss": 0.1669,
      "step": 1030
    },
    {
      "epoch": 2.7733333333333334,
      "grad_norm": 2.4134204387664795,
      "learning_rate": 0.0003843971631205674,
      "loss": 0.216,
      "step": 1040
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.1736949384212494,
      "learning_rate": 0.0003829787234042553,
      "loss": 0.1359,
      "step": 1050
    },
    {
      "epoch": 2.8266666666666667,
      "grad_norm": 1.338593602180481,
      "learning_rate": 0.0003815602836879433,
      "loss": 0.1635,
      "step": 1060
    },
    {
      "epoch": 2.8533333333333335,
      "grad_norm": 6.281895160675049,
      "learning_rate": 0.0003801418439716312,
      "loss": 0.2025,
      "step": 1070
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.018966449424624443,
      "learning_rate": 0.00037872340425531913,
      "loss": 0.1512,
      "step": 1080
    },
    {
      "epoch": 2.9066666666666667,
      "grad_norm": 6.204486846923828,
      "learning_rate": 0.0003773049645390071,
      "loss": 0.1889,
      "step": 1090
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 10.061616897583008,
      "learning_rate": 0.00037588652482269504,
      "loss": 0.2476,
      "step": 1100
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.5354406833648682,
      "learning_rate": 0.00037446808510638297,
      "loss": 0.2049,
      "step": 1110
    },
    {
      "epoch": 2.986666666666667,
      "grad_norm": 0.20458994805812836,
      "learning_rate": 0.0003730496453900709,
      "loss": 0.1501,
      "step": 1120
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.972,
      "eval_f1": 0.972,
      "eval_loss": 0.18840990960597992,
      "eval_precision": 0.972,
      "eval_recall": 0.972,
      "eval_runtime": 3.2893,
      "eval_samples_per_second": 608.03,
      "eval_steps_per_second": 38.002,
      "step": 1125
    },
    {
      "epoch": 3.013333333333333,
      "grad_norm": 0.1105814054608345,
      "learning_rate": 0.0003716312056737589,
      "loss": 0.2071,
      "step": 1130
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.018460359424352646,
      "learning_rate": 0.0003702127659574468,
      "loss": 0.1278,
      "step": 1140
    },
    {
      "epoch": 3.066666666666667,
      "grad_norm": 0.07740744948387146,
      "learning_rate": 0.0003687943262411347,
      "loss": 0.1398,
      "step": 1150
    },
    {
      "epoch": 3.0933333333333333,
      "grad_norm": 2.4007456302642822,
      "learning_rate": 0.00036737588652482265,
      "loss": 0.1473,
      "step": 1160
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.481383353471756,
      "learning_rate": 0.00036595744680851063,
      "loss": 0.1842,
      "step": 1170
    },
    {
      "epoch": 3.1466666666666665,
      "grad_norm": 5.206497669219971,
      "learning_rate": 0.0003645390070921986,
      "loss": 0.145,
      "step": 1180
    },
    {
      "epoch": 3.1733333333333333,
      "grad_norm": 0.029673272743821144,
      "learning_rate": 0.00036312056737588654,
      "loss": 0.1607,
      "step": 1190
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.031556084752082825,
      "learning_rate": 0.0003617021276595745,
      "loss": 0.1456,
      "step": 1200
    },
    {
      "epoch": 3.2266666666666666,
      "grad_norm": 0.13732168078422546,
      "learning_rate": 0.00036028368794326245,
      "loss": 0.1183,
      "step": 1210
    },
    {
      "epoch": 3.2533333333333334,
      "grad_norm": 0.25221574306488037,
      "learning_rate": 0.0003588652482269504,
      "loss": 0.2169,
      "step": 1220
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 9.906716346740723,
      "learning_rate": 0.0003574468085106383,
      "loss": 0.1884,
      "step": 1230
    },
    {
      "epoch": 3.3066666666666666,
      "grad_norm": 0.02740335278213024,
      "learning_rate": 0.0003560283687943263,
      "loss": 0.1322,
      "step": 1240
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.0866478979587555,
      "learning_rate": 0.0003546099290780142,
      "loss": 0.1382,
      "step": 1250
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.1198965311050415,
      "learning_rate": 0.00035319148936170213,
      "loss": 0.1447,
      "step": 1260
    },
    {
      "epoch": 3.3866666666666667,
      "grad_norm": 0.059296347200870514,
      "learning_rate": 0.00035177304964539006,
      "loss": 0.1221,
      "step": 1270
    },
    {
      "epoch": 3.413333333333333,
      "grad_norm": 1.666407823562622,
      "learning_rate": 0.00035035460992907804,
      "loss": 0.2286,
      "step": 1280
    },
    {
      "epoch": 3.44,
      "grad_norm": 7.190270900726318,
      "learning_rate": 0.00034893617021276597,
      "loss": 0.1577,
      "step": 1290
    },
    {
      "epoch": 3.466666666666667,
      "grad_norm": 0.04608343914151192,
      "learning_rate": 0.0003475177304964539,
      "loss": 0.1562,
      "step": 1300
    },
    {
      "epoch": 3.493333333333333,
      "grad_norm": 0.08816585689783096,
      "learning_rate": 0.0003460992907801419,
      "loss": 0.1438,
      "step": 1310
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.496241807937622,
      "learning_rate": 0.0003446808510638298,
      "loss": 0.1776,
      "step": 1320
    },
    {
      "epoch": 3.546666666666667,
      "grad_norm": 6.983689785003662,
      "learning_rate": 0.00034326241134751773,
      "loss": 0.1838,
      "step": 1330
    },
    {
      "epoch": 3.5733333333333333,
      "grad_norm": 0.2525334358215332,
      "learning_rate": 0.00034184397163120565,
      "loss": 0.1816,
      "step": 1340
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.05740104615688324,
      "learning_rate": 0.00034042553191489364,
      "loss": 0.1399,
      "step": 1350
    },
    {
      "epoch": 3.626666666666667,
      "grad_norm": 0.09137597680091858,
      "learning_rate": 0.00033900709219858156,
      "loss": 0.2001,
      "step": 1360
    },
    {
      "epoch": 3.6533333333333333,
      "grad_norm": 0.6145536303520203,
      "learning_rate": 0.0003375886524822695,
      "loss": 0.127,
      "step": 1370
    },
    {
      "epoch": 3.68,
      "grad_norm": 7.023932933807373,
      "learning_rate": 0.0003361702127659574,
      "loss": 0.1653,
      "step": 1380
    },
    {
      "epoch": 3.7066666666666666,
      "grad_norm": 0.022993316873908043,
      "learning_rate": 0.0003347517730496454,
      "loss": 0.1618,
      "step": 1390
    },
    {
      "epoch": 3.7333333333333334,
      "grad_norm": 0.36191537976264954,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.1776,
      "step": 1400
    },
    {
      "epoch": 3.76,
      "grad_norm": 9.079767227172852,
      "learning_rate": 0.00033191489361702125,
      "loss": 0.1699,
      "step": 1410
    },
    {
      "epoch": 3.7866666666666666,
      "grad_norm": 0.22280454635620117,
      "learning_rate": 0.00033049645390070923,
      "loss": 0.2018,
      "step": 1420
    },
    {
      "epoch": 3.8133333333333335,
      "grad_norm": 10.14638900756836,
      "learning_rate": 0.00032907801418439716,
      "loss": 0.1815,
      "step": 1430
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.04696489870548248,
      "learning_rate": 0.0003276595744680851,
      "loss": 0.2137,
      "step": 1440
    },
    {
      "epoch": 3.8666666666666667,
      "grad_norm": 0.056405358016490936,
      "learning_rate": 0.00032624113475177306,
      "loss": 0.1716,
      "step": 1450
    },
    {
      "epoch": 3.8933333333333335,
      "grad_norm": 8.17982292175293,
      "learning_rate": 0.00032482269503546104,
      "loss": 0.1735,
      "step": 1460
    },
    {
      "epoch": 3.92,
      "grad_norm": 7.79447078704834,
      "learning_rate": 0.00032340425531914897,
      "loss": 0.1707,
      "step": 1470
    },
    {
      "epoch": 3.9466666666666668,
      "grad_norm": 0.412143737077713,
      "learning_rate": 0.0003219858156028369,
      "loss": 0.1239,
      "step": 1480
    },
    {
      "epoch": 3.9733333333333336,
      "grad_norm": 10.905984878540039,
      "learning_rate": 0.0003205673758865248,
      "loss": 0.165,
      "step": 1490
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.1913708448410034,
      "learning_rate": 0.0003191489361702128,
      "loss": 0.1988,
      "step": 1500
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9645,
      "eval_f1": 0.9640870005058169,
      "eval_loss": 0.20545563101768494,
      "eval_precision": 0.9754350051177073,
      "eval_recall": 0.953,
      "eval_runtime": 3.2816,
      "eval_samples_per_second": 609.46,
      "eval_steps_per_second": 38.091,
      "step": 1500
    }
  ],
  "logging_steps": 10,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 724994977181184.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
