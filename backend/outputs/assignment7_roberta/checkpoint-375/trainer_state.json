{
  "best_metric": 0.9532530120481928,
  "best_model_checkpoint": "outputs/assignment7_roberta/checkpoint-375",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 375,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 1.3340190649032593,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.7007,
      "step": 10
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.8752999901771545,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.6865,
      "step": 20
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.4065897464752197,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.6954,
      "step": 30
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 2.6209194660186768,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.6902,
      "step": 40
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.4127751588821411,
      "learning_rate": 0.0001111111111111111,
      "loss": 0.6439,
      "step": 50
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.274609088897705,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.4483,
      "step": 60
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 9.437146186828613,
      "learning_rate": 0.00015555555555555556,
      "loss": 0.433,
      "step": 70
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 8.802699089050293,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.2819,
      "step": 80
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.737595558166504,
      "learning_rate": 0.0002,
      "loss": 0.3217,
      "step": 90
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 3.020366907119751,
      "learning_rate": 0.0002222222222222222,
      "loss": 0.3438,
      "step": 100
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 6.522631645202637,
      "learning_rate": 0.00024444444444444443,
      "loss": 0.444,
      "step": 110
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.37520170211792,
      "learning_rate": 0.0002666666666666667,
      "loss": 0.3375,
      "step": 120
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 2.440840244293213,
      "learning_rate": 0.0002888888888888889,
      "loss": 0.2963,
      "step": 130
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 4.665585517883301,
      "learning_rate": 0.0003111111111111111,
      "loss": 0.2949,
      "step": 140
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5990480780601501,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.3042,
      "step": 150
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 4.109732151031494,
      "learning_rate": 0.00035555555555555557,
      "loss": 0.3441,
      "step": 160
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 1.9060498476028442,
      "learning_rate": 0.00037777777777777777,
      "loss": 0.324,
      "step": 170
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.2894931733608246,
      "learning_rate": 0.0004,
      "loss": 0.3104,
      "step": 180
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 1.1362206935882568,
      "learning_rate": 0.0004222222222222222,
      "loss": 0.2622,
      "step": 190
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 4.588229179382324,
      "learning_rate": 0.0004444444444444444,
      "loss": 0.2841,
      "step": 200
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.632187843322754,
      "learning_rate": 0.00046666666666666666,
      "loss": 0.2526,
      "step": 210
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 1.7339062690734863,
      "learning_rate": 0.0004888888888888889,
      "loss": 0.2429,
      "step": 220
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 1.8498952388763428,
      "learning_rate": 0.000499290780141844,
      "loss": 0.2861,
      "step": 230
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.4377846717834473,
      "learning_rate": 0.000497872340425532,
      "loss": 0.2272,
      "step": 240
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 5.9854278564453125,
      "learning_rate": 0.0004964539007092199,
      "loss": 0.2917,
      "step": 250
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 1.3027735948562622,
      "learning_rate": 0.0004950354609929078,
      "loss": 0.3133,
      "step": 260
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0105628967285156,
      "learning_rate": 0.0004936170212765957,
      "loss": 0.2973,
      "step": 270
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 1.355081558227539,
      "learning_rate": 0.0004921985815602837,
      "loss": 0.2032,
      "step": 280
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 1.6863762140274048,
      "learning_rate": 0.0004907801418439716,
      "loss": 0.1674,
      "step": 290
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.8702752590179443,
      "learning_rate": 0.0004893617021276596,
      "loss": 0.348,
      "step": 300
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 4.027673721313477,
      "learning_rate": 0.0004879432624113475,
      "loss": 0.2716,
      "step": 310
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.19163314998149872,
      "learning_rate": 0.0004865248226950355,
      "loss": 0.2113,
      "step": 320
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0682876110076904,
      "learning_rate": 0.0004851063829787234,
      "loss": 0.2816,
      "step": 330
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 2.6967527866363525,
      "learning_rate": 0.00048368794326241133,
      "loss": 0.2354,
      "step": 340
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 1.0981802940368652,
      "learning_rate": 0.00048226950354609925,
      "loss": 0.3244,
      "step": 350
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.7437596321105957,
      "learning_rate": 0.00048085106382978723,
      "loss": 0.2161,
      "step": 360
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.361149400472641,
      "learning_rate": 0.0004794326241134752,
      "loss": 0.2238,
      "step": 370
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9515,
      "eval_f1": 0.9532530120481928,
      "eval_loss": 0.22705689072608948,
      "eval_precision": 0.92,
      "eval_recall": 0.989,
      "eval_runtime": 3.2801,
      "eval_samples_per_second": 609.739,
      "eval_steps_per_second": 38.109,
      "step": 375
    }
  ],
  "logging_steps": 10,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 182893637284224.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
