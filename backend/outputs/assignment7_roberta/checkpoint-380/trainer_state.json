{
  "best_metric": 0.9547738693467337,
  "best_model_checkpoint": "outputs/assignment7_roberta/checkpoint-152",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 380,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 0.5277302861213684,
      "learning_rate": 0.0002173913043478261,
      "loss": 0.6967,
      "step": 10
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 4.463588237762451,
      "learning_rate": 0.0004347826086956522,
      "loss": 0.5687,
      "step": 20
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 6.445164680480957,
      "learning_rate": 0.0004901960784313725,
      "loss": 0.6239,
      "step": 30
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.86,
      "eval_f1": 0.8727272727272727,
      "eval_loss": 0.4587573707103729,
      "eval_precision": 0.8,
      "eval_recall": 0.96,
      "eval_runtime": 0.4182,
      "eval_samples_per_second": 478.275,
      "eval_steps_per_second": 31.088,
      "step": 38
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 4.757599353790283,
      "learning_rate": 0.0004761904761904762,
      "loss": 0.3998,
      "step": 40
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 1.6316391229629517,
      "learning_rate": 0.00046218487394957984,
      "loss": 0.2923,
      "step": 50
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 1.714402675628662,
      "learning_rate": 0.0004481792717086835,
      "loss": 0.29,
      "step": 60
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 1.3598284721374512,
      "learning_rate": 0.00043417366946778713,
      "loss": 0.2865,
      "step": 70
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.945,
      "eval_f1": 0.945273631840796,
      "eval_loss": 0.25023216009140015,
      "eval_precision": 0.9405940594059405,
      "eval_recall": 0.95,
      "eval_runtime": 0.4042,
      "eval_samples_per_second": 494.774,
      "eval_steps_per_second": 32.16,
      "step": 76
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 2.2534539699554443,
      "learning_rate": 0.0004201680672268908,
      "loss": 0.2447,
      "step": 80
    },
    {
      "epoch": 2.3684210526315788,
      "grad_norm": 2.5443997383117676,
      "learning_rate": 0.00040616246498599443,
      "loss": 0.2347,
      "step": 90
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 0.18806765973567963,
      "learning_rate": 0.000392156862745098,
      "loss": 0.2053,
      "step": 100
    },
    {
      "epoch": 2.8947368421052633,
      "grad_norm": 1.7741243839263916,
      "learning_rate": 0.00037815126050420167,
      "loss": 0.2202,
      "step": 110
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.935,
      "eval_f1": 0.9326424870466321,
      "eval_loss": 0.29017484188079834,
      "eval_precision": 0.967741935483871,
      "eval_recall": 0.9,
      "eval_runtime": 0.406,
      "eval_samples_per_second": 492.64,
      "eval_steps_per_second": 32.022,
      "step": 114
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 1.6604423522949219,
      "learning_rate": 0.0003641456582633053,
      "loss": 0.2248,
      "step": 120
    },
    {
      "epoch": 3.4210526315789473,
      "grad_norm": 9.886631965637207,
      "learning_rate": 0.00035014005602240897,
      "loss": 0.1868,
      "step": 130
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 0.3492496609687805,
      "learning_rate": 0.0003361344537815126,
      "loss": 0.1385,
      "step": 140
    },
    {
      "epoch": 3.9473684210526314,
      "grad_norm": 5.141846656799316,
      "learning_rate": 0.00032212885154061626,
      "loss": 0.2734,
      "step": 150
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.955,
      "eval_f1": 0.9547738693467337,
      "eval_loss": 0.25250953435897827,
      "eval_precision": 0.9595959595959596,
      "eval_recall": 0.95,
      "eval_runtime": 0.4068,
      "eval_samples_per_second": 491.601,
      "eval_steps_per_second": 31.954,
      "step": 152
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 4.0200700759887695,
      "learning_rate": 0.0003081232492997199,
      "loss": 0.1402,
      "step": 160
    },
    {
      "epoch": 4.473684210526316,
      "grad_norm": 0.16998690366744995,
      "learning_rate": 0.00029411764705882356,
      "loss": 0.1558,
      "step": 170
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 0.09378727525472641,
      "learning_rate": 0.0002801120448179272,
      "loss": 0.1474,
      "step": 180
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.19693444669246674,
      "learning_rate": 0.0002661064425770308,
      "loss": 0.1496,
      "step": 190
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.95,
      "eval_f1": 0.9494949494949495,
      "eval_loss": 0.26685914397239685,
      "eval_precision": 0.9591836734693877,
      "eval_recall": 0.94,
      "eval_runtime": 0.4085,
      "eval_samples_per_second": 489.647,
      "eval_steps_per_second": 31.827,
      "step": 190
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 0.0661587044596672,
      "learning_rate": 0.00025210084033613445,
      "loss": 0.1227,
      "step": 200
    },
    {
      "epoch": 5.526315789473684,
      "grad_norm": 0.11427228152751923,
      "learning_rate": 0.0002380952380952381,
      "loss": 0.1332,
      "step": 210
    },
    {
      "epoch": 5.7894736842105265,
      "grad_norm": 0.22825796902179718,
      "learning_rate": 0.00022408963585434174,
      "loss": 0.1247,
      "step": 220
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.95,
      "eval_f1": 0.9494949494949495,
      "eval_loss": 0.28218311071395874,
      "eval_precision": 0.9591836734693877,
      "eval_recall": 0.94,
      "eval_runtime": 0.4064,
      "eval_samples_per_second": 492.09,
      "eval_steps_per_second": 31.986,
      "step": 228
    },
    {
      "epoch": 6.052631578947368,
      "grad_norm": 0.07931852340698242,
      "learning_rate": 0.0002100840336134454,
      "loss": 0.1258,
      "step": 230
    },
    {
      "epoch": 6.315789473684211,
      "grad_norm": 0.10715270042419434,
      "learning_rate": 0.000196078431372549,
      "loss": 0.1204,
      "step": 240
    },
    {
      "epoch": 6.578947368421053,
      "grad_norm": 0.06935077905654907,
      "learning_rate": 0.00018207282913165266,
      "loss": 0.1195,
      "step": 250
    },
    {
      "epoch": 6.842105263157895,
      "grad_norm": 0.06570455431938171,
      "learning_rate": 0.0001680672268907563,
      "loss": 0.1211,
      "step": 260
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.945,
      "eval_f1": 0.9447236180904522,
      "eval_loss": 0.276362806558609,
      "eval_precision": 0.9494949494949495,
      "eval_recall": 0.94,
      "eval_runtime": 0.4092,
      "eval_samples_per_second": 488.793,
      "eval_steps_per_second": 31.772,
      "step": 266
    },
    {
      "epoch": 7.105263157894737,
      "grad_norm": 2.217985153198242,
      "learning_rate": 0.00015406162464985996,
      "loss": 0.1235,
      "step": 270
    },
    {
      "epoch": 7.368421052631579,
      "grad_norm": 0.0566600039601326,
      "learning_rate": 0.0001400560224089636,
      "loss": 0.119,
      "step": 280
    },
    {
      "epoch": 7.631578947368421,
      "grad_norm": 8.958495140075684,
      "learning_rate": 0.00012605042016806722,
      "loss": 0.122,
      "step": 290
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 0.033759962767362595,
      "learning_rate": 0.00011204481792717087,
      "loss": 0.1214,
      "step": 300
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.95,
      "eval_f1": 0.95,
      "eval_loss": 0.2842212915420532,
      "eval_precision": 0.95,
      "eval_recall": 0.95,
      "eval_runtime": 0.4103,
      "eval_samples_per_second": 487.427,
      "eval_steps_per_second": 31.683,
      "step": 304
    },
    {
      "epoch": 8.157894736842104,
      "grad_norm": 0.09139922261238098,
      "learning_rate": 9.80392156862745e-05,
      "loss": 0.1207,
      "step": 310
    },
    {
      "epoch": 8.421052631578947,
      "grad_norm": 0.03948086127638817,
      "learning_rate": 8.403361344537815e-05,
      "loss": 0.1186,
      "step": 320
    },
    {
      "epoch": 8.68421052631579,
      "grad_norm": 0.03742896392941475,
      "learning_rate": 7.00280112044818e-05,
      "loss": 0.1185,
      "step": 330
    },
    {
      "epoch": 8.947368421052632,
      "grad_norm": 0.030848592519760132,
      "learning_rate": 5.6022408963585436e-05,
      "loss": 0.1191,
      "step": 340
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.95,
      "eval_f1": 0.9494949494949495,
      "eval_loss": 0.2821559011936188,
      "eval_precision": 0.9591836734693877,
      "eval_recall": 0.94,
      "eval_runtime": 0.4088,
      "eval_samples_per_second": 489.2,
      "eval_steps_per_second": 31.798,
      "step": 342
    },
    {
      "epoch": 9.210526315789474,
      "grad_norm": 0.05860426276922226,
      "learning_rate": 4.201680672268908e-05,
      "loss": 0.1187,
      "step": 350
    },
    {
      "epoch": 9.473684210526315,
      "grad_norm": 0.09755609184503555,
      "learning_rate": 2.8011204481792718e-05,
      "loss": 0.1202,
      "step": 360
    },
    {
      "epoch": 9.736842105263158,
      "grad_norm": 3.2748124599456787,
      "learning_rate": 1.4005602240896359e-05,
      "loss": 0.1204,
      "step": 370
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.04939211905002594,
      "learning_rate": 0.0,
      "loss": 0.1185,
      "step": 380
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.95,
      "eval_f1": 0.9494949494949495,
      "eval_loss": 0.27902185916900635,
      "eval_precision": 0.9591836734693877,
      "eval_recall": 0.94,
      "eval_runtime": 0.4319,
      "eval_samples_per_second": 463.052,
      "eval_steps_per_second": 30.098,
      "step": 380
    }
  ],
  "logging_steps": 10,
  "max_steps": 380,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 172973925483648.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
